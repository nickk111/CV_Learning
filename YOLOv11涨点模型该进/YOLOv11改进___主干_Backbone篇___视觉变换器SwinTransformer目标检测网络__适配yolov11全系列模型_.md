# YOLOv11改进 | 主干/Backbone篇 | 视觉变换器SwinTransformer目标检测网络（ 适配yolov11全系列模型）

## 一、本文介绍

本文给大家带来的改进机制是利用 **Swin Transformer** 替换 **YOLOv11中的骨干网络** 其是一个开创性的视觉变换器模型，它通过使用位移窗口来构建分层的特征图，有效地适应了计算机视觉任务。与传统的变换器模型不同，Swin Transformer的自注意力计算仅限于局部窗口内，使得 **计算复杂度与图像大小成线性关系，而非二次方** 。这种设计不仅提高了模型的效率，还保持了强大的特征提取能力。Swin Transformer的创新在于其能够在不同层次上捕捉图像的细节和全局信息，使其成为各种视觉任务的强大通用骨干网络。 **亲测在小目标检测和大尺度目标检测的数据集上都有涨点效果。**

**（本文内容可根据yolov11的N、S、M、L、X进行二次缩放，轻量化更上一层）**

![](https://i-blog.csdnimg.cn/blog_migrate/42be712554bd30c62e65bf533668cdda.png)

> **专栏回顾： ** ** ** ** ** ** **[YOLOv11改进系列专栏——本专栏持续复习各种顶会内容——科研必备](https://blog.csdn.net/java1314777/category_12798080.html "YOLOv11改进系列专栏——本专栏持续复习各种顶会内容——科研必备")****************

* * *

**目录**

**一、本文介绍**

**二、Swin Transformer原理**

**2.1 Swin Transformer的基本原理**

**2.2 层次化特征映射**

**2.3 局部自注意力计算**

**2.4 移动窗口自注意力**

**2.5 移动窗口分区**

**三、 Swin Transformer的完整代码**

**四、手把手教你添加Swin Transformer网络结构**

**修改一**

**修改二**

**修改三**

**修改四**

**修改五**

**修改六**

**修改七**

**修改八**

****
