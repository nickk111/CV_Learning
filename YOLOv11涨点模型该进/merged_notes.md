# YOLOv11æ”¹è¿› | Conv/å·ç§¯ç¯‡ | åˆ©ç”¨2024æœ€æ–°YOLOv9çš„GELANæ¨¡å—æ›¿æ¢C3k2ç»“æ„ï¼ˆé™„è½»é‡åŒ–ç‰ˆæœ¬ + é«˜æ•ˆæ¶¨ç‚¹ç‰ˆæœ¬ + ç»“æ„å›¾

## ä¸€ã€æœ¬æ–‡ä»‹ç»

æœ¬æ–‡ç»™å¤§å®¶å¸¦æ¥çš„æ”¹è¿›æœºåˆ¶æ˜¯åˆ©ç”¨2024/02/21å·å‘å¸ƒçš„ **YOLOv9å…¶ä¸­æå‡ºçš„GELANæ¨¡å—æ¥æ”¹è¿›YOLOv11ä¸­çš„C3k2** ï¼ŒGELANèåˆäº†CSPNetå’ŒELANæœºåˆ¶åŒæ—¶å…¶ä¸­åˆ©ç”¨åˆ°äº†RepConvåœ¨è·å–æ›´å¤šæœ‰æ•ˆç‰¹å¾çš„åŒæ—¶åœ¨æ¨ç†æ—¶ä¸“ç”¨å•åˆ†æ”¯ç»“æ„ä»è€Œä¸å½±å“æ¨ç†é€Ÿåº¦ï¼ŒåŒæ—¶æœ¬æ–‡çš„å†…å®¹æä¾›äº†ä¸¤ç§ç‰ˆæœ¬ä¸€ç§æ˜¯å‚æ•°é‡æ›´ä½æ¶¨ç‚¹æ•ˆæœç•¥å¾®å¼±ä¸€äº›çš„ç‰ˆæœ¬ï¼Œå¦ä¸€ç§æ˜¯å‚æ•°é‡ç¨å¤šä¸€äº›ä½†æ˜¯æ•ˆæœè¦ä¸å‚æ•°é‡ä½çš„æ•ˆæœè¦å¥½ä¸€äº›ï¼ˆå‡ä¸ºæˆ‘ä¸ªäººæ•´ç†ï¼‰ï¼Œæä¾›ä¸¤ç§ç‰ˆæœ¬æ˜¯ä¸ºäº†é€‚é…ä¸åŒéœ€æ±‚çš„è¯»è€…ï¼Œå…·ä½“é€‰æ‹©é‚£ç§å¤§å®¶å¯ä»¥æ ¹æ®è‡ªèº«çš„éœ€æ±‚æ¥é€‰æ‹©å³å¯ï¼Œæ–‡ç« ä¸­æˆ‘éƒ½å‡å·²æä¾›ï¼Œ **åŒæ—¶æœ¬æ–‡çš„ç»“æ„å­˜åœ¨å¤§é‡çš„äºŒæ¬¡åˆ›æ–°æœºä¼šï¼Œåé¢æˆ‘ä¹Ÿä¼šæä¾›ã€‚**

![](https://i-blog.csdnimg.cn/blog_migrate/71915a55d48a82d02ceb3f48b316b53c.png)

> ** ä¸“æ å›é¡¾ï¼š ** ** **[YOLOv11æ”¹è¿›ç³»åˆ—ä¸“æ â€”â€”æœ¬ä¸“æ æŒç»­å¤ä¹ å„ç§é¡¶ä¼šå†…å®¹â€”â€”ç§‘ç ”å¿…å¤‡](https://blog.csdn.net/java1314777/category_12798080.html "YOLOv11æ”¹è¿›ç³»åˆ—ä¸“æ â€”â€”æœ¬ä¸“æ æŒç»­å¤ä¹ å„ç§é¡¶ä¼šå†…å®¹â€”â€”ç§‘ç ”å¿…å¤‡")********

* * *

**ç›®å½•**

**ä¸€ã€æœ¬æ–‡ä»‹ç»**

**äºŒã€GELANçš„åŸç†**

**2.1 Generalized ELAN**

**2.2 Generalized ELANç»“æ„å›¾**

**ä¸‰ã€æ ¸å¿ƒä»£ç **

**å››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ GELANæœºåˆ¶**

**4.1 ä¿®æ”¹ä¸€**

**4.2 ä¿®æ”¹äºŒ**

**4.3 ä¿®æ”¹ä¸‰**

**4.4 ä¿®æ”¹å››**

**äº”ã€GELANçš„yamlæ–‡ä»¶å’Œè¿è¡Œè®°å½•**

**5.1 GELANä½å‚æ•°é‡ç‰ˆæœ¬çš„yamlæ–‡ä»¶**

**5.2 GELANé«˜å‚æ•°é‡ç‰ˆæœ¬çš„yamlæ–‡ä»¶**

**5.3 è®­ç»ƒä»£ç **

**5.3 GELANçš„è®­ç»ƒè¿‡ç¨‹æˆªå›¾**

**5.3.1 ä½å‚æ•°é‡ç‰ˆæœ¬**

**5.3.2 é«˜å‚æ•°é‡ç‰ˆæœ¬**

**äº”ã€æœ¬æ–‡æ€»ç»“**

* * *

## äºŒã€GELANçš„åŸç†

### 2.1 Generalized ELAN

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬æè¿°äº†æå‡ºçš„æ–°ç½‘ç»œæ¶æ„ - GELANã€‚é€šè¿‡ç»“åˆä¸¤ç§ç¥ç»ç½‘ç»œæ¶æ„CSPNetå’ŒELANï¼Œè¿™ä¸¤ç§æ¶æ„éƒ½æ˜¯ä»¥æ¢¯åº¦è·¯å¾„è§„åˆ’è®¾è®¡çš„ï¼Œæˆ‘ä»¬è®¾è®¡äº†è€ƒè™‘äº†è½»é‡çº§ã€æ¨ç†é€Ÿåº¦å’Œå‡†ç¡®æ€§çš„å¹¿ä¹‰é«˜æ•ˆå±‚èšåˆç½‘ç»œï¼ˆGELANï¼‰ã€‚å…¶æ•´ä½“æ¶æ„å¦‚å›¾4æ‰€ç¤ºã€‚æˆ‘ä»¬æ¨å¹¿äº†ELANçš„èƒ½åŠ›ï¼ŒELANåŸæœ¬åªä½¿ç”¨å·ç§¯å±‚çš„å †å ï¼Œåˆ°ä¸€ä¸ªæ–°çš„æ¶æ„ï¼Œå¯ä»¥ä½¿ç”¨ä»»ä½•è®¡ç®—å—ã€‚

![](https://i-blog.csdnimg.cn/blog_migrate/f36cea552060c3da57ee8ac1fe73b8dc.png)

> è¿™å¼ å›¾ï¼ˆå›¾4ï¼‰å±•ç¤ºäº†å¹¿ä¹‰é«˜æ•ˆå±‚èšåˆç½‘ç»œï¼ˆGELANï¼‰çš„æ¶æ„ï¼Œä»¥åŠå®ƒæ˜¯å¦‚ä½•ä»CSPNetå’ŒELANè¿™ä¸¤ç§ç¥ç»ç½‘ç»œæ¶æ„æ¼”å˜è€Œæ¥çš„ã€‚è¿™ä¸¤ç§æ¶æ„éƒ½è®¾è®¡æœ‰æ¢¯åº¦è·¯å¾„è§„åˆ’ã€‚
> 
> **a) CSPNetï¼š** åœ¨CSPNetçš„æ¶æ„ä¸­ï¼Œè¾“å…¥é€šè¿‡ä¸€ä¸ªè½¬æ¢å±‚è¢«åˆ†å‰²ä¸ºä¸¤éƒ¨åˆ†ï¼Œç„¶ååˆ†åˆ«é€šè¿‡ä»»æ„çš„è®¡ç®—å—ã€‚ä¹‹åï¼Œè¿™äº›åˆ†æ”¯è¢«é‡æ–°åˆå¹¶ï¼ˆé€šè¿‡concatenationï¼‰ï¼Œå¹¶å†æ¬¡é€šè¿‡è½¬æ¢å±‚ã€‚
> 
> **b) ELANï¼š** ä¸CSPNetç›¸æ¯”ï¼ŒELANé‡‡ç”¨äº†å †å çš„å·ç§¯å±‚ï¼Œå…¶ä¸­æ¯ä¸€å±‚çš„è¾“å‡ºéƒ½ä¼šä¸ä¸‹ä¸€å±‚çš„è¾“å…¥ç›¸ç»“åˆï¼Œå†ç»è¿‡å·ç§¯å¤„ç†ã€‚
> 
> **c) GELANï¼š** ç»“åˆäº†CSPNetå’ŒELANçš„è®¾è®¡ï¼Œæå‡ºäº†GELANã€‚å®ƒé‡‡ç”¨äº†CSPNetçš„åˆ†å‰²å’Œé‡ç»„çš„æ¦‚å¿µï¼Œå¹¶åœ¨æ¯ä¸€éƒ¨åˆ†å¼•å…¥äº†ELANçš„å±‚çº§å·ç§¯å¤„ç†æ–¹å¼ã€‚ä¸åŒä¹‹å¤„åœ¨äºGELANä¸ä»…ä½¿ç”¨å·ç§¯å±‚ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ä»»ä½•è®¡ç®—å—ï¼Œä½¿å¾—ç½‘ç»œæ›´åŠ çµæ´»ï¼Œèƒ½å¤Ÿæ ¹æ®ä¸åŒçš„åº”ç”¨éœ€æ±‚å®šåˆ¶ã€‚
> 
> GELANçš„è®¾è®¡è€ƒè™‘åˆ°äº†è½»é‡åŒ–ã€æ¨ç†é€Ÿåº¦å’Œç²¾ç¡®åº¦ï¼Œä»¥æ­¤æ¥æé«˜æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚å›¾ä¸­æ˜¾ç¤ºçš„æ¨¡å—å’Œåˆ†åŒºçš„å¯é€‰æ€§è¿›ä¸€æ­¥å¢åŠ äº†ç½‘ç»œçš„é€‚åº”æ€§å’Œå¯å®šåˆ¶æ€§ã€‚GELANçš„è¿™ç§ç»“æ„å…è®¸å®ƒæ”¯æŒå¤šç§ç±»å‹çš„è®¡ç®—å—ï¼Œè¿™ä½¿å¾—å®ƒå¯ä»¥æ›´å¥½åœ°é€‚åº”å„ç§ä¸åŒçš„è®¡ç®—éœ€æ±‚å’Œç¡¬ä»¶çº¦æŸã€‚
> 
> æ€»çš„æ¥è¯´ï¼ŒGELANçš„æ¶æ„æ˜¯ä¸ºäº†æä¾›ä¸€ä¸ªæ›´åŠ é€šç”¨å’Œé«˜æ•ˆçš„ç½‘ç»œï¼Œå¯ä»¥é€‚åº”ä»è½»é‡çº§åˆ°å¤æ‚çš„æ·±åº¦å­¦ä¹ ä»»åŠ¡ï¼ŒåŒæ—¶ä¿æŒæˆ–å¢å¼ºè®¡ç®—æ•ˆç‡å’Œæ€§èƒ½ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒGELANæ—¨åœ¨è§£å†³ç°æœ‰æ¶æ„çš„é™åˆ¶ï¼Œæä¾›ä¸€ä¸ªå¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆï¼Œä»¥é€‚åº”æœªæ¥æ·±åº¦å­¦ä¹ çš„å‘å±•ã€‚
> 
> **å¤§å®¶çœ‹å›¾ç‰‡ä¸€çœ¼å°±èƒ½çœ‹å‡ºæ¥å®ƒèåˆäº†ä»€ä¹ˆï¼Œå°±æ˜¯å°†CSPHetçš„anyBlockæ¨¡å—å †å çš„æ–¹å¼å’ŒELANèåˆåˆ°äº†ä¸€èµ·ã€‚**

* * *

### 2.2 Generalized ELANç»“æ„å›¾

YOLOv9æœ€ä¸»è¦çš„åˆ›æ–°ç›®å‰èƒ½å¤Ÿå¾—åˆ°çš„å°±æ˜¯å…¶ä¸­çš„ **GELANç»“æ„ ï¼Œæˆ‘ä¹Ÿæ˜¯åˆ†æå…¶ä»£ç æ ¹æ®è®ºæ–‡å°†å…¶ç»“æ„å›¾ç»˜ç”»å‡ºæ¥ã€‚**

ä¸‹é¢çš„æ–‡ä»¶ä¸ºYOLOv9çš„yamlæ–‡ä»¶ã€‚å¯ä»¥çœ‹åˆ°çš„æ˜¯å…¶æå‡ºäº†ä¸€ç§ç»“æ„åå­—RepNCSPELAN4ï¼Œå…¶ä¸­çš„ç»“æ„å›¾concatåçš„é€šé“æ•°æˆ‘æ²¡æœ‰ç”»æ˜¯å› ä¸ºå®ƒæœ‰è®¡ç®—ä¸­é—´çš„å‚æ•°çš„å˜é‡æ˜¯æ ¹æ®ä¸ªäººè®¾ç½®æ¥çš„ã€‚ 

**å…¶ä»£ç å’Œç»“æ„å›¾å¦‚ä¸‹æ‰€ç¤ºï¼**
    
    
    class RepNCSPELAN4(nn.Module):    # csp-elan    def __init__(self, c1, c2, c5=1):  # c5 = repeat        super().__init__()        c3 = int(c2 / 2)        c4 = int(c3 / 2)        self.c = c3 // 2        self.cv1 = Conv(c1, c3, 1, 1)        self.cv2 = nn.Sequential(RepNCSP(c3 // 2, c4, c5), Conv(c4, c4, 3, 1))        self.cv3 = nn.Sequential(RepNCSP(c4, c4, c5), Conv(c4, c4, 3, 1))        self.cv4 = Conv(c3 + (2 * c4), c2, 1, 1)     def forward(self, x):        y = list(self.cv1(x).chunk(2, 1))        y.extend((m(y[-1])) for m in [self.cv2, self.cv3])        return self.cv4(torch.cat(y, 1))     def forward_split(self, x):        y = list(self.cv1(x).split((self.c, self.c), 1))        y.extend(m(y[-1]) for m in [self.cv2, self.cv3])        return self.cv4(torch.cat(y, 1))

![](https://i-blog.csdnimg.cn/blog_migrate/d084f472a88af6c756c785721d1fb8f7.png)

* * *

## ä¸‰ã€æ ¸å¿ƒä»£ç  

**æ ¸å¿ƒä»£ç çš„ä½¿ç”¨æ–¹å¼çœ‹ç« èŠ‚å››ï¼**
    
    
    import torchimport torch.nn as nnimport numpy as np __all__ = ['RepNCSPELAN4_low', 'RepNCSPELAN4_high']  class RepConvN(nn.Module):    """RepConv is a basic rep-style block, including training and deploy status    This code is based on https://github.com/DingXiaoH/RepVGG/blob/main/repvgg.py    """    default_act = nn.SiLU()  # default activation     def __init__(self, c1, c2, k=3, s=1, p=1, g=1, d=1, act=True, bn=False, deploy=False):        super().__init__()        assert k == 3 and p == 1        self.g = g        self.c1 = c1        self.c2 = c2        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()         self.bn = None        self.conv1 = Conv(c1, c2, k, s, p=p, g=g, act=False)        self.conv2 = Conv(c1, c2, 1, s, p=(p - k // 2), g=g, act=False)     def forward_fuse(self, x):        """Forward process"""        return self.act(self.conv(x))     def forward(self, x):        """Forward process"""        id_out = 0 if self.bn is None else self.bn(x)        return self.act(self.conv1(x) + self.conv2(x) + id_out)     def get_equivalent_kernel_bias(self):        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.conv1)        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.conv2)        kernelid, biasid = self._fuse_bn_tensor(self.bn)        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid     def _avg_to_3x3_tensor(self, avgp):        channels = self.c1        groups = self.g        kernel_size = avgp.kernel_size        input_dim = channels // groups        k = torch.zeros((channels, input_dim, kernel_size, kernel_size))        k[np.arange(channels), np.tile(np.arange(input_dim), groups), :, :] = 1.0 / kernel_size ** 2        return k     def _pad_1x1_to_3x3_tensor(self, kernel1x1):        if kernel1x1 is None:            return 0        else:            return torch.nn.functional.pad(kernel1x1, [1, 1, 1, 1])     def _fuse_bn_tensor(self, branch):        if branch is None:            return 0, 0        if isinstance(branch, Conv):            kernel = branch.conv.weight            running_mean = branch.bn.running_mean            running_var = branch.bn.running_var            gamma = branch.bn.weight            beta = branch.bn.bias            eps = branch.bn.eps        elif isinstance(branch, nn.BatchNorm2d):            if not hasattr(self, 'id_tensor'):                input_dim = self.c1 // self.g                kernel_value = np.zeros((self.c1, input_dim, 3, 3), dtype=np.float32)                for i in range(self.c1):                    kernel_value[i, i % input_dim, 1, 1] = 1                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)            kernel = self.id_tensor            running_mean = branch.running_mean            running_var = branch.running_var            gamma = branch.weight            beta = branch.bias            eps = branch.eps        std = (running_var + eps).sqrt()        t = (gamma / std).reshape(-1, 1, 1, 1)        return kernel * t, beta - running_mean * gamma / std     def fuse_convs(self):        if hasattr(self, 'conv'):            return        kernel, bias = self.get_equivalent_kernel_bias()        self.conv = nn.Conv2d(in_channels=self.conv1.conv.in_channels,                              out_channels=self.conv1.conv.out_channels,                              kernel_size=self.conv1.conv.kernel_size,                              stride=self.conv1.conv.stride,                              padding=self.conv1.conv.padding,                              dilation=self.conv1.conv.dilation,                              groups=self.conv1.conv.groups,                              bias=True).requires_grad_(False)        self.conv.weight.data = kernel        self.conv.bias.data = bias        for para in self.parameters():            para.detach_()        self.__delattr__('conv1')        self.__delattr__('conv2')        if hasattr(self, 'nm'):            self.__delattr__('nm')        if hasattr(self, 'bn'):            self.__delattr__('bn')        if hasattr(self, 'id_tensor'):            self.__delattr__('id_tensor')  class RepNBottleneck(nn.Module):    # Standard bottleneck    def __init__(self, c1, c2, shortcut=True, g=1, k=(3, 3), e=0.5):  # ch_in, ch_out, shortcut, kernels, groups, expand        super().__init__()        c_ = int(c2 * e)  # hidden channels        self.cv1 = RepConvN(c1, c_, k[0], 1)        self.cv2 = Conv(c_, c2, k[1], 1, g=g)        self.add = shortcut and c1 == c2     def forward(self, x):        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))  class RepNCSP(nn.Module):    # CSP Bottleneck with 3 convolutions    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion        super().__init__()        c_ = int(c2 * e)  # hidden channels        self.cv1 = Conv(c1, c_, 1, 1)        self.cv2 = Conv(c1, c_, 1, 1)        self.cv3 = Conv(2 * c_, c2, 1)  # optional act=FReLU(c2)        self.m = nn.Sequential(*(RepNBottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))     def forward(self, x):        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))  def autopad(k, p=None, d=1):  # kernel, padding, dilation    # Pad to 'same' shape outputs    if d > 1:        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]  # actual kernel-size    if p is None:        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad    return p  class Conv(nn.Module):    # Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation)    default_act = nn.SiLU()  # default activation     def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):        super().__init__()        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)        self.bn = nn.BatchNorm2d(c2)        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()     def forward(self, x):        return self.act(self.bn(self.conv(x)))     def forward_fuse(self, x):        return self.act(self.conv(x))  class RepNCSPELAN4_low(nn.Module):    # csp-elan    def __init__(self, c1, c2, c5=1):  # c5 = repeat        super().__init__()        c3 = int(c2 / 2)        c4 = int(c3 / 2)        self.c = c3 // 2        self.cv1 = Conv(c1, c3, 1, 1)        self.cv3 = nn.Sequential(RepNCSP(c3, c3, c5))        self.cv4 = Conv(c3 + (2 * c4), c2, 1, 1)     def forward(self, x):        temp = self.cv1(x)        temp3 = self.cv3(temp)        y = list(temp.chunk(2, 1))        y.append(temp3)        temp2 = torch.cat(y, 1)        return self.cv4(temp2)     def forward_split(self, x):        y = list(self.cv1(x).split((self.c, self.c), 1))        y.extend(m(y[-1]) for m in [self.cv2, self.cv3])        return self.cv4(torch.cat(y, 1))  class RepNCSPELAN4_high(nn.Module):    # csp-elan    def __init__(self, c1, c2, c5=1):  # c5 = repeat        super().__init__()        c3 = c2        c4 = int(c3 / 2)        self.c = c3 // 2        self.cv1 = Conv(c1, c3, 1, 1)        self.cv2 = nn.Sequential(RepNCSP(c3 // 2, c4, c5), Conv(c4, c4, 3, 1))        self.cv3 = nn.Sequential(RepNCSP(c4, c4, c5), Conv(c4, c4, 3, 1))        self.cv4 = Conv(c3 + (2 * c4), c2, 1, 1)     def forward(self, x):        y = list(self.cv1(x).chunk(2, 1))        y.extend((m(y[-1])) for m in [self.cv2, self.cv3])        return self.cv4(torch.cat(y, 1))     def forward_split(self, x):        y = list(self.cv1(x).split((self.c, self.c), 1))        y.extend(m(y[-1]) for m in [self.cv2, self.cv3])        return self.cv4(torch.cat(y, 1))  if __name__ == "__main__":    # Generating Sample image    image_size = (1, 24, 224, 224)    image = torch.rand(*image_size)     # Model    mobilenet_v1 = RepNCSPELAN4_low(24, 24)     out = mobilenet_v1(image)    print(out.size())

* * *

## å››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ GELANæœºåˆ¶ 

### 4.1 ä¿®æ”¹ä¸€

ç¬¬ä¸€è¿˜æ˜¯å»ºç«‹æ–‡ä»¶ï¼Œæˆ‘ä»¬æ‰¾åˆ°å¦‚ä¸‹ultralytics/nn/modulesæ–‡ä»¶å¤¹ä¸‹å»ºç«‹ä¸€ä¸ªç›®å½•åå­—å‘¢å°±æ˜¯'Addmodules'æ–‡ä»¶å¤¹( **ç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€æ–°å»º)** ï¼ç„¶ååœ¨å…¶å†…éƒ¨å»ºç«‹ä¸€ä¸ªæ–°çš„pyæ–‡ä»¶å°†æ ¸å¿ƒä»£ç å¤åˆ¶ç²˜è´´è¿›å»å³å¯ã€‚

![](https://i-blog.csdnimg.cn/blog_migrate/06f13b45e9be8ac3feae96980a68fef8.png)



* * *

### 4.2 ä¿®æ”¹äºŒ 

ç¬¬äºŒæ­¥æˆ‘ä»¬åœ¨è¯¥ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–°çš„pyæ–‡ä»¶åå­—ä¸º'__init__.py'( **ç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€æ–°å»º)** ï¼Œç„¶ååœ¨å…¶å†…éƒ¨å¯¼å…¥æˆ‘ä»¬çš„æ£€æµ‹å¤´å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![](https://i-blog.csdnimg.cn/blog_migrate/64ad768bd566d474d4ccfa755517d254.png)

* * *

### 4.3 ä¿®æ”¹ä¸‰ 

ç¬¬ä¸‰æ­¥æˆ‘é—¨ä¸­åˆ°å¦‚ä¸‹æ–‡ä»¶'ultralytics/nn/tasks.py'è¿›è¡Œå¯¼å…¥å’Œæ³¨å†Œæˆ‘ä»¬çš„æ¨¡å—( **ç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€é‡æ–°å¯¼å…¥ç›´æ¥å¼€å§‹ç¬¬å››æ­¥å³å¯)** ï¼

**ä»ä»Šå¤©å¼€å§‹ä»¥åçš„æ•™ç¨‹å°±éƒ½ç»Ÿä¸€æˆè¿™ä¸ªæ ·å­äº†ï¼Œå› ä¸ºæˆ‘é»˜è®¤å¤§å®¶ç”¨äº†æˆ‘ç¾¤å†…çš„æ–‡ä»¶æ¥è¿›è¡Œä¿®æ”¹ï¼ï¼**

![](https://i-blog.csdnimg.cn/blog_migrate/1c5002145da93a67bd05854d0d51f81f.png)

* * *

### 4.4 ä¿®æ”¹å›› 

æŒ‰ç…§æˆ‘çš„æ·»åŠ åœ¨parse_modelé‡Œæ·»åŠ å³å¯ã€‚

![](https://i-blog.csdnimg.cn/blog_migrate/4e5a6a26be276ac6f3fef4564030e49f.png)

**åˆ°æ­¤å°±ä¿®æ”¹å®Œæˆäº†ï¼Œå¤§å®¶å¯ä»¥å¤åˆ¶ä¸‹é¢çš„yamlæ–‡ä»¶è¿è¡Œã€‚**

* * *

## äº”ã€GELANçš„yamlæ–‡ä»¶å’Œè¿è¡Œè®°å½•

### 5.1 GELANä½å‚æ•°é‡ç‰ˆæœ¬çš„yamlæ–‡ä»¶

> **æ­¤ç‰ˆæœ¬è®­ç»ƒä¿¡æ¯ï¼šYOLO11-RepGELAN-low summary: 403 layers, 2,218,027 parameters, 2,218,011 gradients, 6.3 GFLOPs**


    # Ultralytics YOLO ğŸš€, AGPL-3.0 license# YOLO11 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect # Parametersnc: 80 # number of classesscales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n'  # [depth, width, max_channels]  n: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs  s: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs  m: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs  l: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs  x: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs # YOLO11n backbonebackbone:  # [from, repeats, module, args]  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4  - [-1, 2, RepNCSPELAN4_low, [256]]  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8  - [-1, 2, RepNCSPELAN4_low, [512]]  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16  - [-1, 2, RepNCSPELAN4_low, [512]]  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32  - [-1, 2, RepNCSPELAN4_low, [1024]]  - [-1, 1, SPPF, [1024, 5]] # 9  - [-1, 2, C2PSA, [1024]] # 10 # YOLO11n headhead:  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  - [[-1, 6], 1, Concat, [1]] # cat backbone P4  - [-1, 2, RepNCSPELAN4_low, [512]] # 13   - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  - [[-1, 4], 1, Concat, [1]] # cat backbone P3  - [-1, 2, RepNCSPELAN4_low, [256]] # 16 (P3/8-small)   - [-1, 1, Conv, [256, 3, 2]]  - [[-1, 13], 1, Concat, [1]] # cat head P4  - [-1, 2, RepNCSPELAN4_low, [512]] # 19 (P4/16-medium)   - [-1, 1, Conv, [512, 3, 2]]  - [[-1, 10], 1, Concat, [1]] # cat head P5  - [-1, 2, RepNCSPELAN4_low, [1024]] # 22 (P5/32-large)   - [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)

* * *

### 5.2 GELANé«˜å‚æ•°é‡ç‰ˆæœ¬çš„yamlæ–‡ä»¶

> **æ­¤ç‰ˆæœ¬è®­ç»ƒä¿¡æ¯ï¼šYOLO11-RepGELAN-high summary: 651 layers, 3,837,803 parameters, 3,837,787 gradients, 12.1 GFLOPs**


    # Ultralytics YOLO ğŸš€, AGPL-3.0 license# YOLO11 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect # Parametersnc: 80 # number of classesscales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n'  # [depth, width, max_channels]  n: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs  s: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs  m: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs  l: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs  x: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs # YOLO11n backbonebackbone:  # [from, repeats, module, args]  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4  - [-1, 2, RepNCSPELAN4_high, [256]]  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8  - [-1, 2, RepNCSPELAN4_high, [512]]  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16  - [-1, 2, RepNCSPELAN4_high, [512]]  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32  - [-1, 2, RepNCSPELAN4_high, [1024]]  - [-1, 1, SPPF, [1024, 5]] # 9  - [-1, 2, C2PSA, [1024]] # 10 # YOLO11n headhead:  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  - [[-1, 6], 1, Concat, [1]] # cat backbone P4  - [-1, 2, RepNCSPELAN4_high, [512]] # 13   - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  - [[-1, 4], 1, Concat, [1]] # cat backbone P3  - [-1, 2, RepNCSPELAN4_high, [256]] # 16 (P3/8-small)   - [-1, 1, Conv, [256, 3, 2]]  - [[-1, 13], 1, Concat, [1]] # cat head P4  - [-1, 2, RepNCSPELAN4_high, [512]] # 19 (P4/16-medium)   - [-1, 1, Conv, [512, 3, 2]]  - [[-1, 10], 1, Concat, [1]] # cat head P5  - [-1, 2, RepNCSPELAN4_high, [1024]] # 22 (P5/32-large)   - [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)

* * *

### 5.3 è®­ç»ƒä»£ç  

å¤§å®¶å¯ä»¥åˆ›å»ºä¸€ä¸ªpyæ–‡ä»¶å°†æˆ‘ç»™çš„ä»£ç å¤åˆ¶ç²˜è´´è¿›å»ï¼Œé…ç½®å¥½è‡ªå·±çš„æ–‡ä»¶è·¯å¾„å³å¯è¿è¡Œã€‚
    
    
    import warningswarnings.filterwarnings('ignore')from ultralytics import YOLO if __name__ == '__main__':    model = YOLO('ultralytics/cfg/models/v8/yolov8-C2f-FasterBlock.yaml')    # model.load('yolov8n.pt') # loading pretrain weights    model.train(data=r'æ›¿æ¢æ•°æ®é›†yamlæ–‡ä»¶åœ°å€',                # å¦‚æœå¤§å®¶ä»»åŠ¡æ˜¯å…¶å®ƒçš„'ultralytics/cfg/default.yaml'æ‰¾åˆ°è¿™é‡Œä¿®æ”¹taskå¯ä»¥æ”¹æˆdetect, segment, classify, pose                cache=False,                imgsz=640,                epochs=150,                single_cls=False,  # æ˜¯å¦æ˜¯å•ç±»åˆ«æ£€æµ‹                batch=4,                close_mosaic=10,                workers=0,                device='0',                optimizer='SGD', # using SGD                # resume='', # å¦‚è¿‡æƒ³ç»­è®­å°±è®¾ç½®last.ptçš„åœ°å€                amp=False,  # å¦‚æœå‡ºç°è®­ç»ƒæŸå¤±ä¸ºNanå¯ä»¥å…³é—­amp                project='runs/train',                name='exp',                )

### 

* * *

### 5.3 GELANçš„è®­ç»ƒè¿‡ç¨‹æˆªå›¾ 

#### 5.3.1 ä½å‚æ•°é‡ç‰ˆæœ¬

![](https://i-blog.csdnimg.cn/direct/bca1d35e59fd4ebab2dbce914aecc04e.png)

* * *

#### 5.3.2 é«˜å‚æ•°é‡ç‰ˆæœ¬

![](https://i-blog.csdnimg.cn/direct/e1ee022b9a53415689ac6913b7c0acfe.png)

* * *

## äº”ã€æœ¬æ–‡æ€»ç»“

åˆ°æ­¤æœ¬æ–‡çš„æ­£å¼åˆ†äº«å†…å®¹å°±ç»“æŸäº†ï¼Œåœ¨è¿™é‡Œç»™å¤§å®¶æ¨èæˆ‘çš„YOLOv11æ”¹è¿›æœ‰æ•ˆæ¶¨ç‚¹ä¸“æ ï¼Œæœ¬ä¸“æ ç›®å‰ä¸ºæ–°å¼€çš„å¹³å‡è´¨é‡åˆ†98åˆ†ï¼ŒåæœŸæˆ‘ä¼šæ ¹æ®å„ç§æœ€æ–°çš„å‰æ²¿é¡¶ä¼šè¿›è¡Œè®ºæ–‡å¤ç°ï¼Œä¹Ÿä¼šå¯¹ä¸€äº›è€çš„æ”¹è¿›æœºåˆ¶è¿›è¡Œè¡¥å……ï¼Œå¦‚æœå¤§å®¶è§‰å¾—æœ¬æ–‡å¸®åŠ©åˆ°ä½ äº†ï¼Œè®¢é˜…æœ¬ä¸“æ ï¼Œå…³æ³¨åç»­æ›´å¤šçš„æ›´æ–°~ 
